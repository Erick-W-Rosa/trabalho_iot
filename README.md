A simula√ß√£o de 20 dispositivos IoT foi realizada utilizando um script Python (simulacao_iot.py), onde cada dispositivo enviou um pacote de dados simulados com tempo de rede aleat√≥rio entre 0,05 e 0,2 segundos. Uma taxa de falha de 5% foi aplicada para representar perdas reais de transmiss√£o.

Ap√≥s a execu√ß√£o, obteve-se o seguinte:

<img width="596" height="478" alt="image" src="https://github.com/user-attachments/assets/c5c2d32b-8dd0-49a2-bbee-bc330475d965" />

https://github.com/user-attachments/assets/b1b4be7b-87eb-4a00-9f2c-cdcfca43311c

E se aument√°ssemos para 1000 dispositivos?

Se o mesmo script fosse rodado sequencialmente (um dispositivo por vez), surgiriam v√°rios problemas:

1Ô∏è‚É£ Tempo total de simula√ß√£o ficaria muito alto

Com 20 dispositivos ‚Üí ~2,4 segundos
Com 1000 dispositivos:

üìå 1000 √ó 0.12 s ‚âà 120 segundos (2 minutos)
Somente esperando sleep.

Isso inviabiliza cen√°rios ‚Äúreais‚Äù, onde v√°rios dispositivos enviam simultaneamente.

2Ô∏è‚É£ Maior probabilidade de perdas reais de transmiss√£o

Num sistema real (n√£o no script):

- excesso de conex√µes simult√¢neas ‚Üí congestionamento

- timeouts ‚Üí pacotes descartados

- buffers cheios ‚Üí falha de processamento

- servidor pode rejeitar requisi√ß√µes

Mesmo que o script use perda aleat√≥ria, no mundo real a taxa de perda subiria.

3Ô∏è‚É£ Impacto mais pesado na CPU

Com 1000 dispositivos:

- mais loops

- mais logs

- mais eventos para processar

- poss√≠veis gargalos no interpretador Python

Se usar threads/async, o n√∫mero de context switches aumenta, consumindo CPU.

4Ô∏è‚É£ Crescimento no uso de RAM

Se voc√™ armazenar:

- resultados

- logs

- buffers de mensagens

- filas de envio

O consumo de mem√≥ria pode subir r√°pido.

5Ô∏è‚É£ Limites do sistema operacional

Em simula√ß√µes paralelas reais:

- limite de sockets simult√¢neos

- limite de file descriptors

- filas de rede podem encher

- risco de travar o programa por thread storm

üß† Conclus√£o para entregar no trabalho

Ao escalar de 20 para 1000 dispositivos, o sistema come√ßaria a apresentar problemas de desempenho, principalmente devido ao aumento do tempo total de envio, maior carga na CPU, maior consumo de RAM e poss√≠veis gargalos na capacidade de conex√µes simult√¢neas. Em sistemas reais, isso exigiria t√©cnicas como envio ass√≠ncrono, filas de mensagens (MQTT, Kafka, RabbitMQ), balanceamento de carga e mecanismos de retry/backoff.



O trabalho basicamente pede para simular entre 5 e 20 dispositivos IoT enviando dados, e depois medir tr√™s coisas: o tempo m√©dio de envio, a taxa de perda e o impacto no computador. A ideia √© usar tempos aleat√≥rios e uma chance de falha para imitar o comportamento de uma rede real, onde atrasos e erros acontecem naturalmente.

A parte mais desafiadora √© entender como representar esses dispositivos de forma simulada, como coletar as m√©tricas e, principalmente, como interpretar o que esses n√∫meros significam. Al√©m disso, o trabalho pede uma an√°lise de como tudo mudaria se, em vez de (5 a 20), tiv√©ssemos 1000 dispositivos enviando dados ao mesmo tempo. Isso faz perceber problemas reais que aparecem em sistemas IoT maiores, como aumento de lat√™ncia, mais falhas de envio, limita√ß√µes de hardware e dificuldades de escalabilidade.

